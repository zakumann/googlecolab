{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04.이미지분석 샘플.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6pPW-_wsM3mp",
        "outputId": "b1acf3d6-05e3-4b33-e4e0-1eeb13f84fbc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import keras\n",
        "keras.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from  google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ubpMDpD0NtZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c26e0a1f-08b1-4c41-a819-c9da933ec2c9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil"
      ],
      "metadata": {
        "id": "LJBJutUPXfgg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원본 데이터셋을 압축 해제한 디렉터리 경로\n",
        "original_dataset_dir = './drive/MyDrive/datasets/cats_and_dogs/train'\n",
        "\n",
        "# 소규모 데이터셋을 저장할 디렉터리\n",
        "base_dir = './drive/MyDrive/datasets/cats_and_dogs_small'\n",
        "#if os.path.exists(base_dir): \n",
        "#    shutil.rmtree(base_dir)  \n",
        "#os.mkdir(base_dir)\n",
        "\n",
        "# 훈련, 검증, 테스트 분할을 위한 디렉터리\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "#os.mkdir(train_dir)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "#os.mkdir(validation_dir)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "#os.mkdir(test_dir)\n",
        "\n",
        "# 훈련용 고양이 사진 디렉터리\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "#os.mkdir(train_cats_dir)\n",
        "# 훈련용 강아지 사진 디렉터리\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "#os.mkdir(train_dogs_dir)\n",
        "\n",
        "# 검증용 고양이 사진 디렉터리\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "#os.mkdir(validation_cats_dir)\n",
        "# 검증용 강아지 사진 디렉터리\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "#os.mkdir(validation_dogs_dir)\n",
        "\n",
        "#테스트용 고양이 사진 디렉터리\n",
        "test_cats_dir = os.path.join(test_dir, 'cats')\n",
        "#os.mkdir(test_cats_dir)\n",
        "#테스트용 강아지 사진 디렉터리\n",
        "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
        "#os.mkdir(test_dogs_dir)\n",
        "\n",
        "# 처음 1000개의 고양이 이미지를 train_cats_dir에 복사합니다. \n",
        "print('Copy files.... ')\n",
        "print('---traing file(s) (cat).... ')\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
        "for fname in fnames:\n",
        "  src = os.path.join(original_dataset_dir, fname)\n",
        "  dst = os.path.join(train_cats_dir, fname)\n",
        "#  shutil.copyfile(src, dst)\n",
        "\n",
        "# 다음 500개 고양이 이미지를 validation_cats_dir 복사합니다. \n",
        "\n",
        "print('---validation file(s) (cat).... ')\n",
        "\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
        "\n",
        "for fname in fnames:\n",
        "\n",
        "  src = os.path.join(original_dataset_dir, fname)\n",
        "\n",
        "  dst = os.path.join(validation_cats_dir, fname)\n",
        "\n",
        "  shutil.copyfile(src, dst)\n",
        "\n",
        "\n",
        "\n",
        "# 다음 500개 고양이 이미지를 test_cats_dir 복사합니다. \n",
        "\n",
        "print('---test file(s) (cat).... ')\n",
        "\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
        "\n",
        "for fname in fnames:\n",
        "\n",
        "  src = os.path.join(original_dataset_dir, fname)\n",
        "\n",
        "  dst = os.path.join(validation_cats_dir, fname)\n",
        "\n",
        "  shutil.copyfile(src, dst)"
      ],
      "metadata": {
        "id": "NERw9SlYbvhJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e91fdd70-c2a8-4bc5-ce37-baec0c71a1d7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copy files.... \n",
            "---traing file(s) (cat).... \n",
            "---validation file(s) (cat).... \n",
            "---test file(s) (cat).... \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('훈련용 고양이 이미지 전체 개수:', len(os.listdir(train_cats_dir)))\n",
        "print('검증용 고양이 이미지 전체 개수:', len(os.listdir(validation_cats_dir)))\n",
        "print('테스트용 고양이 이미지 전체 개수:', len(os.listdir(test_cats_dir)))\n",
        "print('훈련용 강아지 이미지 전체 개수:', len(os.listdir(train_dogs_dir)))\n",
        "print('검증용 강아지 이미지 전체 개수:', len(os.listdir(validation_dogs_dir)))\n",
        "print('테스트용 강아지 이미지 전체 개수:', len(os.listdir(test_dogs_dir)))"
      ],
      "metadata": {
        "id": "4gimA-GHeJkM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4895e99b-8f51-40a0-8be2-118e677a5baa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련용 고양이 이미지 전체 개수: 0\n",
            "검증용 고양이 이미지 전체 개수: 1000\n",
            "테스트용 고양이 이미지 전체 개수: 0\n",
            "훈련용 강아지 이미지 전체 개수: 0\n",
            "검증용 강아지 이미지 전체 개수: 0\n",
            "테스트용 강아지 이미지 전체 개수: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32,(3,3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(128, (3,3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(128, (3,3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "so_91LVCGUrk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alh-95cDIQX2",
        "outputId": "8b7a0071-d29f-4f99-e8e2-f6bd04cf512e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150,150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(150,150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMw18kJWIcpV",
        "outputId": "273c7ccc-e1ef-4a86-8be2-abfed463ac73"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    epochs=30,\n",
        "    steps_per_epoch=100,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=50\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "NUpoyDO4LYfm",
        "outputId": "ef77ef2d-a951-44b9-e741-cf5f8985bd35"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-4fb873dee5dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2221\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2223\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2225\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     55\u001b[0m                              \u001b[0;34m'but the Sequence '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                              'has length {length}'.format(idx=idx,\n\u001b[0;32m---> 57\u001b[0;31m                                                           length=len(self)))\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_batches_seen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Asked to retrieve element 0, but the Sequence has length 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('cats_and_dogs_small_1.h5')"
      ],
      "metadata": {
        "id": "gJTlfMcSU0VH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.history\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "OLT1SUwNVOfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# 이미지 전처리 유틸리티 모듈\n",
        "from keras.preprocessing import image\n",
        "\n",
        "fnames = sorted([os.path.join(train_cats_dir, fname) for fname in os.listdir(train_cats_dir)])\n",
        "\n",
        "# 증식할 이미지 선택합니다\n",
        "img_path = fnames[3]\n",
        "\n",
        "# 이미지를 읽고 크기를 변경합니다\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "\n",
        "# (150, 150, 3) 크기의 넘파이 배열로 변환합니다\n",
        "x = image.img_to_array(img)\n",
        "\n",
        "# (1, 150, 150, 3) 크기로 변환합니다\n",
        "x = x.reshape((1,) + x.shape)\n",
        "\n",
        "# flow() 메서드는 랜덤하게 변환된 이미지의 배치를 생성합니다.\n",
        "# 무한 반복되기 때문에 어느 지점에서 중지해야 합니다!\n",
        "i = 0\n",
        "for batch in datagen.flow(x, batch_size=1):\n",
        "    plt.figure(i)\n",
        "    imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
        "    i += 1\n",
        "    if i % 4 == 0:\n",
        "        break"
      ],
      "metadata": {
        "id": "FZO6p7TnXB2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                        input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])"
      ],
      "metadata": {
        "id": "4zeiwAPEZfmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,)\n",
        "\n",
        "# 검증 데이터는 증식되어서는 안 됩니다!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # 타깃 디렉터리\n",
        "        train_dir,\n",
        "        # 모든 이미지를 150 × 150 크기로 바꿉니다\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        # binary_crossentropy 손실을 사용하기 때문에 이진 레이블을 만들어야 합니다\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n",
        "\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=100,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=50)"
      ],
      "metadata": {
        "id": "LFJ4zp15ZhiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "l2l8jN3caIc4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}